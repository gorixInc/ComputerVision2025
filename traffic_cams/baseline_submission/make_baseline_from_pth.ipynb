{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0675dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from traffic_cams.non_max_suppression import nms_xywh\n",
    "from traffic_cams.util import targets_to_results\n",
    "from traffic_cams.model import AdvancedObjectDetector\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1db9e73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"GPU is not available, using CPU instead\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71ce9a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['passenger_car', 'pedestrian', 'bus', 'tram', 'utility_vehicle', 'lorry']\n",
    "anchors = [] # (K, n_anchros, 2)\n",
    "for c in classes:\n",
    "    anchors.append([[0.0530, 0.0304],\n",
    "                    [0.0957, 0.0671],\n",
    "                    [0.1610, 0.1170],\n",
    "                    [0.2561, 0.1953],\n",
    "                    [0.4059, 0.3488],\n",
    "                    [0.6490, 0.7201]])  # Anchors relative to image size\n",
    "model_img_width = int(1280/2)\n",
    "model_img_height =  int(704/2)\n",
    "\n",
    "anchors = np.array(anchors)\n",
    "model = AdvancedObjectDetector(len(classes), num_anchors=anchors.shape[1], backbone='efficientnet_b7')\n",
    "stride = model.get_stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3ff921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'best_efficennet_b7_70ep_baseline'\n",
    "state_dict = torch.load(f'traffic_cams/baseline_submission/{checkpoint_name}.pth', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict['model_state_dict'])\n",
    "model.eval()\n",
    "history = state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "940285c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_paths = glob(\"traffic_cams/datasets/to_kaggle/test_images/images/*.jpg\")  # Replace the path here\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((model_img_height, model_img_width)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "model.to(device)\n",
    "out_data = {'image_id':[], \n",
    "            'confidence':[],\n",
    "            'class_name':[],\n",
    "            'x_min':[],\n",
    "            'y_min':[],\n",
    "            'x_max':[],\n",
    "            'y_max':[]}\n",
    "for i in range(len(test_img_paths)):\n",
    "    path = test_img_paths[i]\n",
    "    img_id = Path(path).stem\n",
    "    image = Image.open(path,mode='r') \n",
    "    transf_image = transform(image).unsqueeze(0).to(device)\n",
    "    pred_targets = model.forward(transf_image).cpu().detach()\n",
    "    class_ids, confidences, bboxes = targets_to_results(pred_targets[0], anchors, len(classes), stride=stride,\n",
    "                                    model_h=model_img_height, model_w=model_img_width, H=720, W=1280)\n",
    "    class_ids, confidences, bboxes = nms_xywh(class_ids, confidences, bboxes, score_threshold=0.25, iou_threshold=0.2)\n",
    "    for i in range(len(class_ids)):\n",
    "        class_id = class_ids[i]\n",
    "        conf = confidences[i]\n",
    "        x, y, w, h = bboxes[i]\n",
    "        class_id = int(class_id)\n",
    "        out_data['image_id'].append(img_id)\n",
    "        out_data['confidence'].append(conf)\n",
    "        out_data['class_name'].append(classes[class_id])\n",
    "        out_data['x_min'].append(x-w/2)\n",
    "        out_data['y_min'].append(y-h/2)\n",
    "        out_data['x_max'].append(x+w/2)\n",
    "        out_data['y_max'].append(y+h/2)\n",
    "        \n",
    "df = pd.DataFrame(out_data)\n",
    "\n",
    "# Generate submission here\n",
    "df.to_csv(f'traffic_cams/baseline_submission.csv', index_label='ID', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
